{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import zipfile\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_persist_pdf() -> Chroma:\n",
    "    pdf_folder_path = \"./pdfs/\"\n",
    "    documents = []\n",
    "    for file in os.listdir(pdf_folder_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder_path, file)\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    client = chromadb.Client()\n",
    "    if client.list_collections():\n",
    "        consent_collection = client.create_collection(\"consent_collection\")\n",
    "    else:\n",
    "        print(\"Collection already exists\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=chunked_documents,\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        persist_directory=\"./chroma_store\"\n",
    "    )\n",
    "    vectordb.persist()\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_chain():\n",
    "    model_name = \"gpt-3.5-turbo\"\n",
    "    llm = ChatOpenAI(model_name=model_name)\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(query, vectordb):\n",
    "    chain = create_agent_chain()\n",
    "    matching_docs = vectordb.similarity_search(query)\n",
    "    answer = chain.run(input_documents=matching_docs, question=query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_folder(folder_path, output_path):\n",
    "    \"\"\"\n",
    "    Compresses a folder into a ZIP file.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path: The path to the folder that should be compressed.\n",
    "    - output_path: The path where the output ZIP file should be saved.\n",
    "    \"\"\"\n",
    "    # Create a ZIP file for writing compressed data\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk through the directory\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create a relative path for files to maintain the directory structure\n",
    "                rel_path = os.path.relpath(os.path.join(root, file), os.path.dirname(folder_path))\n",
    "                zipf.write(os.path.join(root, file), arcname=rel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_folder(\"./chroma_store\", \"chroma_store.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection already exists\n"
     ]
    }
   ],
   "source": [
    "res = load_chunk_persist_pdf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'sqlite3.Connection' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mvector_db.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(res, f)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'sqlite3.Connection' object"
     ]
    }
   ],
   "source": [
    "with open('vector_db.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of the study is to promote and strengthen measures to prevent and combat corruption more efficiently and effectively, promote international cooperation and technical assistance in the prevention of and fight against corruption, including asset recovery, and to promote integrity, accountability, and proper management of public affairs and public property.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_response(\"What is the purpose of this study?\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
